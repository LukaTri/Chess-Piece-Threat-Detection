{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a2cfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pyvirtualdisplay\n",
    "mpl.rc('animation', html='jshtml')\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862f6cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfb88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.seed(42)\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82c870f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01258566, -0.00156614,  0.04207708, -0.00180545])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a54f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pyvirtualdisplay\n",
    "    display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ccf6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994869ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = env.render(mode=\"rgb_array\")\n",
    "#img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb3f90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef plot_environment(env, figsize=(5,4)):\\n    plt.figure(figsize=figsize)\\n    img = env.render(mode=\"rgb_array\")\\n    plt.imshow(img)\\n    plt.axis(\"off\")\\n    return img\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def plot_environment(env, figsize=(5,4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    img = env.render(mode=\"rgb_array\")\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    return img\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c86200d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplot_environment(env)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plot_environment(env)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30e64e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.seed(42)\n",
    "\n",
    "def basic_policy(obs):\n",
    "    angle = obs[2]\n",
    "    return 0 if angle < 0 else 1\n",
    "\n",
    "totals = []\n",
    "for episode in range(50):\n",
    "    episode_rewards = 0\n",
    "    obs = env.reset()\n",
    "    for step in range(50):\n",
    "        action = basic_policy(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_rewards += reward\n",
    "        if done:\n",
    "            break\n",
    "    totals.append(episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "085d03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.seed(4)\n",
    "\n",
    "#frames = []\n",
    "\n",
    "obs = env.reset()\n",
    "for step in range(200):\n",
    "    #img = env.render(mode=\"rgb_array\")\n",
    "    #frames.append(img)\n",
    "    action = basic_policy(obs)\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "924eedd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef update_scene(num, frames, patch):\\n    patch.set_data(frames[num])\\n    return patch,\\n\\ndef plot_animation(frames, repeat=False, interval=40):\\n    fig = plt.figure()\\n    patch = plt.imshow(frames[0])\\n    plt.axis('off')\\n    anim = animation.FuncAnimation(\\n        fig, update_scene, fargs=(frames, patch),\\n        frames=len(frames), repeat=repeat, interval=interval)\\n    plt.close()\\n    return anim\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=40):\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update_scene, fargs=(frames, patch),\n",
    "        frames=len(frames), repeat=repeat, interval=interval)\n",
    "    plt.close()\n",
    "    return anim\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d684c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_animation(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "996de176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Now we are going to create the nerual network that will take observations as inputs, then output the probability, p,of going left (0), and the probability, 1-p, of going right (1).'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Now we are going to create the nerual network that will take observations as inputs, then output the probability, p,of going left (0), and the probability, 1-p, of going right (1).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "583a6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "n_inputs = 4 #  == env.observatoin_space.shape[0]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(5, activation='elu', input_shape=[n_inputs]),\n",
    "    keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a32c3970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_step(env, obs, model, loss_fn):\n",
    "    with tf.GradientTape() as tape:\n",
    "        left_proba = model(obs[np.newaxis])\n",
    "        action = (tf.random.uniform([1,1])) > left_proba\n",
    "        y_target = tf.constant([[1.]]) - tf.cast(action, tf.float32)\n",
    "        loss = tf.reduce_mean(loss_fn(y_target, left_proba))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    obs, rewards, done, info = env.step(int(action[0,0].numpy()))\n",
    "    return obs, reward, done, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf422c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_multiple_episodes(env, n_episodes, n_max_steps, model, loss_fn):\n",
    "    all_rewards = []\n",
    "    all_grads = []\n",
    "    for episode in range(n_episodes):\n",
    "        current_rewards = []\n",
    "        current_grads = []\n",
    "        obs = env.reset()\n",
    "        for step in range(n_max_steps):\n",
    "            obs, rewards, done, grads = play_one_step(env, obs, model, loss_fn)\n",
    "            current_rewards.append(rewards)\n",
    "            current_grads.append(grads)\n",
    "            if done:\n",
    "                break\n",
    "        all_rewards.append(current_rewards)\n",
    "        all_grads.append(current_grads)\n",
    "    return all_rewards, all_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14430cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, discount_factor):\n",
    "    discounted = np.array(rewards)\n",
    "    for step in range(len(rewards) -2, -1, -1):\n",
    "        discounted[step] += discounted[step + 1] * discount_factor\n",
    "    return discounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c6dd780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_and_normalize_rewards(all_rewards, discount_factor):\n",
    "    all_discounted_rewards = [discount_rewards(rewards, discount_factor)\n",
    "                             for rewards in all_rewards]\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = flat_rewards.mean()\n",
    "    reward_std = flat_rewards.std()\n",
    "    return [(discounted_rewards - reward_mean) / reward_std\n",
    "           for discounted_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aec169f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-22, -40, -50])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_rewards([10, 0, -50], discount_factor=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67bd24ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.28435071, -0.86597718, -1.18910299]),\n",
       " array([1.26665318, 1.0727777 ])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_and_normalize_rewards([[10, 0, -50], [10, 20]],\n",
    "                              discount_factor=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39921330",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 150\n",
    "n_episodes_per_update = 10\n",
    "n_max_steps = 200\n",
    "discount_factor = 0.95\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "741d2caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 149, mean rewards: 190.8"
     ]
    }
   ],
   "source": [
    "for iteration in range(n_iterations):\n",
    "    all_rewards, all_grads = play_multiple_episodes(\n",
    "    env, n_episodes_per_update, n_max_steps, model, loss_fn)\n",
    "    \n",
    "    total_rewards = sum(map(sum, all_rewards))                     # Not shown in the book\n",
    "    print(\"\\rIteration: {}, mean rewards: {:.1f}\".format(          # Not shown\n",
    "        iteration, total_rewards / n_episodes_per_update), end=\"\") # Not shown\n",
    "    \n",
    "    all_final_rewards = discount_and_normalize_rewards(all_rewards,\n",
    "                                                      discount_factor)\n",
    "    all_mean_grads = []\n",
    "    for var_index in range(len(model.trainable_variables)):\n",
    "        mean_grads = tf.reduce_mean(\n",
    "        [final_reward * all_grads[episode_index][step][var_index]\n",
    "         for episode_index, final_rewards in enumerate(all_final_rewards)\n",
    "         for step, final_reward in enumerate(final_rewards)], axis=0)\n",
    "        all_mean_grads.append(mean_grads)\n",
    "    optimizer.apply_gradients(zip(all_mean_grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "124fb85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800293e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
